#!/usr/bin/env python3.6
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 15 13:58:08 2018

@author: winkleram
"""

import os, sys, numpy, pydicom, json, datetime, random, shutil

# Defaults --------------------------------------------------------------------
nidbDir = '/nidb/'
tempDir = os.path.join(nidbDir,'tmp')

def printHelp(): # ============================================================
    # Print help
    print("Wrapper around dcm2niix, to be used inside NiDB.\n" + \
          "Adds AcquisitionDateTime to JSON and handles multi-echo scans.")

def updateProgress(progress): # ===============================================
    barLength = 50
    status = ""
    if isinstance(progress, int):
        progress = float(progress)
    if not isinstance(progress, float):
        progress = 0
        status = "Error: progress var must be float.\r\n"
    if progress < 0:
        progress = 0
        status = "Halt...\r\n"
    if progress >= 1:
        progress = 1
        status = "Done.\r\n"
    block = int(round(barLength*progress))
    text = "\rPercent: [{0}] {1}% {2}".format( "#"*block + "-"*(barLength-block), round(progress*100), status)
    sys.stdout.write(text)
    sys.stdout.flush()

def returnTagValue(x, tag): # =================================================
    # Return the content of a tag of a DICOM file, or of a previously
    # loaded DICOM header.
    if   isinstance(x, str):
        dicomHdr = pydicom.read_file(x, stop_before_pixels=True)
    elif isinstance(x, pydicom.dataset.FileDataset):
        dicomHdr = x
    Tag = pydicom.tag.Tag(tag);
    if Tag in dicomHdr:
        tagValue = dicomHdr[Tag].value
    else:
        tagValue = None
    return tagValue

def sortMultiEcho(allFileNames): # ============================================
    # Sort the DICOM files from the working directory
    dicomHdr     = pydicom.read_file(allFileNames[0], stop_before_pixels=True)
    nImages      = int      (returnTagValue(dicomHdr, ('0020','1002')))
    nRepetitions = int      (returnTagValue(dicomHdr, ('0020','0105')))
    nSlices      = int      (returnTagValue(dicomHdr, ('0021','104f')))
    EchoTime0    = float    (returnTagValue(dicomHdr, ('0018','0081')))
    echoTimeDiff = float    (returnTagValue(dicomHdr, ('0019','10ac')))
    nEchoes      = int(float(returnTagValue(dicomHdr, ('0019','10a9'))))
    nEchoesCalc  = int(nImages / nSlices)
    nImagesExp   = nImages * nRepetitions
    nImagesDir   = len(allFileNames)
    print("Number of echoes, from the header:   %s"   % nEchoes)
    print("Number of echoes, calculated:        %s"   % nEchoesCalc)
    print("Number of slices:                    %s"   % nSlices)
    print("Number of slices * echoes:           %s"   % nImages)
    print("Number of repetitions is:            %s"   % nRepetitions)
    print("Expected number of images:           %s"   % nImagesExp)
    print("Number of images in directory:       %s"   % nImagesDir)
    print("Time of first echo (ms):             %s"   % EchoTime0)
    print("Time difference between echoes (ms): %s\n" % echoTimeDiff)

    # Each slice an index number. The following while loop reads files until it
    # finds nImages distinct index numbers
    sliceIndexList = list()
    fileCount = 0
    while len(sliceIndexList) < nImages:
        # sliceIndex is the counter from the first to last of nImages (across echoes and slices and volumes)
        sliceIndex = int(returnTagValue(allFileNames[fileCount], ('0019','10a2')))
        if sliceIndex not in sliceIndexList:
            sliceIndexList.append(sliceIndex)
        fileCount += 1
    sliceIndexList.sort()

    if( nImages % nSlices ):  # i.e. if there is a remainder from this division
        sys.exit("Error: There seem to be some un-accounted for slices.\n" \
                 "       Either the scan is not complete, or there\n" \
                 "       was an error with the data organization.")
    else:
        sliceIndexList = numpy.reshape(sliceIndexList, [nEchoes, nImages//nEchoes])

    # Track all SOP instance UIDs.
    if len(allFileNames) > (nImages*nRepetitions):
        print("Warning: Sometimes GE multi-echo DICOM series have replicated slices.")
        print("         These will be sorted out below.")

    imageInstanceUIDList     = list()
    multiEchoFilesSortedDict = dict()
    imageCount = 1
    for file2Process in allFileNames:
        imageInstanceUID = returnTagValue(file2Process, ('0008','0018'))
        sliceIndex       = returnTagValue(file2Process, ('0019','10a2'))
        if imageInstanceUID not in imageInstanceUIDList:
            imageInstanceUIDList.append(imageInstanceUID)
            multiEchoFilesSortedDict[imageInstanceUID] = [file2Process, sliceIndex]
        # Give some indication of progress
        if (imageCount % round(nImagesExp/100) == 0) or (imageCount == nImagesExp):
            updateProgress(imageCount/nImagesExp)
        imageCount += 1
    print("")

    if len(allFileNames) > (nImages*nRepetitions):
        print("After sorting out duplicates, number of images is: %s" % len(imageInstanceUIDList))
        print("Number of entries in dictionary is:                %s" % len(multiEchoFilesSortedDict))

    # At this time, we should have a dictionary of all of the files we need to
    # sort, and used to build multi-echo AFNI or NIFTI data sets.  Now, use this
    # dictionary(as it is already in memory) to do the final sorting of image
    # files.  At this point, we should not need to read anything from disk, but
    # should be able to move files to their correct locations / echo directories.
    print("Sorting images by echo and moving into sub-directories.")
    for EchoIdx in range(0, nEchoes):
        dirName = "echo_%04d" % (EchoIdx + 1)
        os.mkdir(dirName)
    imageCount = 1
    for sopIDs in multiEchoFilesSortedDict.keys():
        sliceIndex = multiEchoFilesSortedDict[sopIDs][1]
        for EchoIdx in range(0, nEchoes):
            dirName = "echo_%04d" % (EchoIdx + 1)
            if sliceIndex in sliceIndexList[EchoIdx]:
                os.rename(multiEchoFilesSortedDict[sopIDs][0],
                          os.path.join(dirName, multiEchoFilesSortedDict[sopIDs][0]))
                break
        # Give some indication of progress
        if (imageCount % round(nImagesExp/100) == 0) or (imageCount == nImagesExp):
            updateProgress(imageCount/nImagesExp)
        imageCount += 1
    print("")

def convertToNifti(opts, outDir, randStr, inDir, # ===========================================
                   EchoTime=None, AcqDateTime=None,
                   BandwidthPerPixelPhaseEncode=None):
    cmd = "{} {} -f {} {}".format(os.path.join(nidbDir, 'bin', 'dcm2niix.original'), ' '.join(opts), randStr, inDir)
    print("Converting to NIFTI.")
    print("Running the following command:\n{}".format(cmd))
    if not os.path.exists(outDir):
        os.makedirs(outDir)
    status = os.system(cmd)
    if status == 0:
        #jsonfile = os.path.join(outDir, '{}.json'.format(randStr))
        jsonfiles = [j for j in os.listdir(outDir) if j.endswith(".json")]
        for jsonfile in jsonfiles:
            if (EchoTime != None or AcqDateTime != None):
                with open(os.path.join(outDir,jsonfile)) as f:
                    json_data = json.load(f)
                if EchoTime != None and Manufacturer == 'GE MEDICAL SYSTEMS':
                    json_data['EchoTime'] = EchoTime/1000
                if AcqDateTime != None:
                    json_data['AcquisitionDateTime'] = AcqDateTime
                    json_data.pop('AcquisitionTime', None)
                if not 'EffectiveEchoSpacing' in json_data and \
                   BandwidthPerPixelPhaseEncode != None and \
                   'ReconMatrixPE' in json_data:
                    json_data['EffectiveEchoSpacing'] = 1/(BandwidthPerPixelPhaseEncode*json_data['ReconMatrixPE'])
                if not 'TotalReadoutTime' in json_data and \
                   'EffectiveEchoSpacing' in json_data and \
                   'ReconMatrixPE' in json_data:
                    json_data['TotalReadoutTime'] = json_data['EffectiveEchoSpacing']*(json_data['ReconMatrixPE']-1)
                with open(os.path.join(outDir,jsonfile), 'w') as f:
                    json_data = json.dump(json_data, f, indent=2)
    else:
        sys.exit("Error: Conversion to NIFTI failed.")

# ======== [ Main ] ===========================================================
if __name__ == '__main__':
    if hasattr(os, 'sync'):
        sync = os.sync
    else:
        import ctypes, platform
        if platform.uname()[0] != "Darwin":
            libc = ctypes.CDLL("libc.so.6")
        else:
            libc = ctypes.CDLL("/usr/lib/libc.dylib")
        def sync():
           libc.sync()

    if len(sys.argv) <= 1:
        printHelp()
        sys.exit()
    argv   = sys.argv
    #argv   = '/nidb/bin/dcm2niixme -1 -b y -z y -o /home/nidb/nifti /home/nidb/dicom'
    #argv   = argv.split(' ')
    inDir  = argv[-1]
    opts   = argv[1:-1]
    idx    = opts.index('-o')
    outDir = opts[idx+1]

    # Define a temporary directory, to be used in lieu of the archive directory
    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
    randStr  = ''.join(random.choices(alphabet, k=10))
    workDir  = os.path.join(tempDir, randStr)
    os.makedirs(workDir)

    # Create symlinks that will be the inputs
    sys.stderr.write('Processing .dcm files in directory {}\n'.format(inDir))
    allFileNames = [f for f in os.listdir(inDir) if f.endswith(".dcm")]
    if len(allFileNames) == 0:
        sys.exit("Error: No files with extension .dcm were found in {}.".format(inDir))
    for f in allFileNames:
        os.symlink(os.path.join(inDir, f), os.path.join(workDir, f))
    os.chdir(workDir)
    allFileNames.sort()
    print("First DICOM file is: {}".format(allFileNames[0]))

    # Test manufacturer
    dicomHdr = pydicom.read_file(allFileNames[0], stop_before_pixels=True)
    Manufacturer = returnTagValue(dicomHdr, ('0008','0070'))
    print('Manufacturer: {}'.format(Manufacturer))

    # Get and reformat acquisition date and time
    AcqDate      = returnTagValue(dicomHdr, ('0008','0022'))
    AcqTime      = returnTagValue(dicomHdr, ('0008','0032'))
    if isinstance(AcqDate, str) and isinstance(AcqTime, str):
        AcqDate      = datetime.datetime.strptime(AcqDate,"%Y%m%d").strftime("%Y-%m-%d")
        AcqTime      = datetime.datetime.strptime(AcqTime.split('.')[0],"%H%M%S").strftime("%H:%M:%S")
        AcqDateTime  = '{}T{}'.format(AcqDate, AcqTime)
    else:
        AcqDateTime = None

    # Siemens provides this field, used to compute EffectiveEchoSpacing as 1/(BWPPPE * ReconMatrixPE) 
    BandwidthPerPixelPhaseEncode = returnTagValue(dicomHdr, ('0019','1028'))
    if isinstance(BandwidthPerPixelPhaseEncode, str):
        BandwidthPerPixelPhaseEncode = eval(BandwidthPerPixelPhaseEncode)
    else:
        BandwidthPerPixelPhaseEncode = None

    # Check number of echoes and sort accordingly
    nEchoes = returnTagValue(dicomHdr, ('0019','10a9'))
    if nEchoes != None:
        nEchoes = int(float(nEchoes))
    if nEchoes == None or nEchoes <= 1 or nEchoes >= 200: # Localizer has 240 in the nEchoes tag
        convertToNifti(opts, outDir, randStr, workDir, EchoTime=None, AcqDateTime=AcqDateTime)
    else:
        EchoTime0    = float(returnTagValue(dicomHdr, ('0018','0081')))
        echoTimeDiff = float(returnTagValue(dicomHdr, ('0019','10ac')))
        sortMultiEcho(allFileNames)
        for EchoIdx in range(0, nEchoes):
            dirEcho   = "echo_%04d" % (EchoIdx + 1)
            s = convertToNifti(opts, outDir, randStr + str(EchoIdx + 1),
                           os.path.join(workDir, dirEcho),
                           EchoTime=EchoTime0 + EchoIdx*echoTimeDiff,
                           AcqDateTime=AcqDateTime)

    # Delete the working directory
    shutil.rmtree(workDir)
